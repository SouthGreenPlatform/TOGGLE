#!/usr/bin/env perl

###################################################################################################################################
#
# This pipeline was automatically generated by TOGGLEv3 onTheFly version.
#
##################################################################################################################################

###################################################################################################################################
#
# Copyright 2014-2018 IRD-CIRAD-INRA-ADNid
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, see <http://www.gnu.org/licenses/> or
# write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston,
# MA 02110-1301, USA.
#
# You should have received a copy of the CeCILL-C license with this program.
#If not see <http://www.cecill.info/licences/Licence_CeCILL-C_V1-en.txt>
#
# Intellectual property belongs to IRD, CIRAD and South Green developpement plateform for all versions also for ADNid for v2 and v3 and INRA for v3
# Version 1 written by Cecile Monat, Ayite Kougbeadjo, Christine Tranchant, Cedric Farcy, Mawusse Agbessi, Maryline Summo, and Francois Sabot
# Version 2 written by Cecile Monat, Christine Tranchant, Cedric Farcy, Enrique Ortega-Abboud, Julie Orjuela-Bouniol, Sebastien Ravel, Souhila Amanzougarene, and Francois Sabot
# Version 3 written by Cecile Monat, Christine Tranchant, Laura Helou, Abdoulaye Diallo, Julie Orjuela-Bouniol, Sebastien Ravel, Gautier Sarah, and Francois Sabot
#
###################################################################################################################################

# Perl Modules
use strict;
use warnings 'all';
no warnings 'experimental';
use Data::Dumper;
use Switch;
use Getopt::ArgParse;

#TOGGLE Modules
use localConfig;
use bwa;
use cutadapt;
use fastqc;
use fastqUtils;
use fastxToolkit;
use gatk;
use pairing;
use picardTools;
use samTools;
use toolbox;
use onTheFly;
use tophat;
use HTSeq;
use tgicl;
use trinity;
use radseq;
use bamutils;
use atropos;
use crac;
use bowtie;
use scp;
use duplicationDetector;
use bedTools;
use generic;
use abyss;
use breakDancer;
use pindel;
use plink;
use sniplay;
use fastme;
use readseq;
use stats;
use eaUtils;
use hisat2;
use stringtie;
use nanoplot;

##########################################
# recovery of parameters/arguments given when the program is executed
##########################################
my $cmd_line=$0." @ARGV"; # for printing in log file

my $parser = Getopt::ArgParse->new_parser(
        prog            => "\n\ntoggleBzz.pl",
        description     => '',
        epilog          => "
##########################################################################
# More information:
#\thttps://github.com/SouthGreenPlatform/TOGGLE/blob/master/docs/README.md
#
#\tCITATION:
#\tTOGGLe, a flexible framework for easily building complex workflows and performing robust large-scale NGS analyses.
#\tChristine Tranchant-Dubreuil, Sebastien Ravel, Cecile Monat, Gautier Sarah, Abdoulaye Diallo, Laura Helou, Alexis Dereeper,
#\tNdomassi Tando, Julie Orjuela-Bouniol, Francois Sabot.
#\tbioRxiv, doi: https://doi.org/10.1101/245480
#\thttps://toggle.southgreen.fr/
###########################################################################\n",
        help            => 'a framework to build quickly NGS pipelines',
        error_prefix    => "\n\tERROR MSG: "
);


$parser->add_args(
                    [
                        '-c','--config',
                        required => 1,
                        type     =>"Scalar",
                        metavar  => "FILE",
                        help     => 'Software configuration file',
                        dest     => 'config'
                    ],
                    [
                        '-d','--directory',
                        required => 1,
                        type     => "Scalar",
                        metavar  => "DIR",
                        help     => 'Directory name with the files to analyse',
                        dest     => 'directory'
                    ],
                    [
                        '-nocheck','--nocheckFastq',
                        required => 0,
                        type     =>"Bool",
                        help     => 'Use if you did not check fastq file',
                        dest     => 'checkFastq'
                    ],
                    [
                        '-g','--gff',
                        required => 0,
                        type     =>"Scalar",
                        metavar  => "FILE",
                        help     => 'gff file name used by topHat for example',
                        dest     => 'gff',
                        default  => "None"
                    ],
                    [
                        '-k','--keyfile',
                        required => 0,
                        type     =>"Scalar",
                        metavar  => "FILE",
                        help     => 'keyfile file name used by radseq (demultiplexing step)',
                        dest     => 'keyfile',
                        default  => "None"
                    ],
                    [
                        '-r','--reference',
                        required => 0,
                        type     =>"Scalar",
                        metavar  => "FILE",
                        help     => 'Reference file name',
                        dest     => 'reference',
                        default  => "None"
                    ],
                    [
                        '-report','--report',
                        required => 0,
                        type     =>"Bool",
                        help     => 'Use if you want to generate workflow an analysis reports',
                        dest     => 'report'
                    ],
                    [
                        '-rerun','--rerun',
                        required => 0,
                        type     => "Bool",
                        help     => "Restart the analysis from the last successful step",
                    ]
                );
# for print usage "or die" in help
#my $usage = $parser->format_usage();
#my $help = join ("\n", @$usage);

my $args = $parser->parse_args();
#recovery supplementary arguments undefined by toggle
my @argv= $parser->argv;




#Recovery obligatory arguments
my $initialDir = toolbox::relativeToAbsolutePath($parser->namespace->directory, 0);       # recovery of the name of the directory to analyse
my $fileConf = toolbox::relativeToAbsolutePath($parser->namespace->config, 0);            # recovery of the name of the software.configuration.txt file

#Recovery optional arguments
my $refFastaFile = toolbox::relativeToAbsolutePath($parser->namespace->reference, 0);   # recovery of the reference file
my $gffFile = toolbox::relativeToAbsolutePath($parser->namespace->gff, 0);              # recovery of the gff file used by topHat and rnaseq analysis
my $keyfile = toolbox::relativeToAbsolutePath($parser->namespace->keyfile, 0);          # recovery of the keyfile used by radseq

#verify if -nocheckfastq arguments exist in args. The fastq format is verified par default if $checkFastq == 0.
# WARNING with the parser : if nocheckfastq argument is add then $checkFastq == 1
my $checkFastq = $parser->namespace->checkFastq;
my $report = $parser->namespace->report;
my $rerun = $parser->namespace->rerun;

my @listFilesMandatory=($initialDir, $fileConf); #stock mandatory files to test if they exist
push (@listFilesMandatory,$refFastaFile) if $refFastaFile !~ m/None$/;
push (@listFilesMandatory,$gffFile) if $gffFile !~ m/None$/;
push (@listFilesMandatory,$keyfile) if $keyfile !~ m/None$/;

# Verify if file arguments exist
foreach my $file (@listFilesMandatory)
{
  toolbox::checkFile($file); #check file
}

toolbox::existsDir($initialDir);        # exit with an error if the initial dir does not exist


##########################################
# Creation of IndividuSoft.txt for creation of logs files later
##########################################
my @pathIndividu = toolbox::extractPath($initialDir);
my $readGroup = $pathIndividu[0];
if ($0 =~ m/toggleMultiple/)
{
  #The script will be running for a globalAnalysis thus we must change the readGroup value
  $readGroup = "globalAnalysis";
}
chdir "$initialDir";

# Creating log file
my $logFile=$initialDir."/".$readGroup."_log.o";
my $errorFile=$initialDir."/".$readGroup."_log.e";
system("touch $logFile $errorFile") and die "\nERROR: $0 : cannot create the log files $logFile and $errorFile: $!\nExiting...\n";

# Determine the name of the file containing the last successful step
my $stepFileName=$initialDir."/.".$readGroup."_last_step";
my $stepFileHandle;
# This will contain the last successful step when using rerun
my $lastOkStep;


toolbox::exportLog("#########################################\nINFOS: TOGGLE analysis start \n#########################################\n",1);
toolbox::exportLog("INFOS: Initial command line : $cmd_line\n",1);

my $initialFileList = toolbox::readDir($initialDir);

my $previousDir = $initialDir."/0_initialFiles";

if ($rerun)
{
  # If the initialFiles folder does not exist, the analysis has not started at all
  if (! -d $previousDir)
  {
    toolbox::exportLog("ERROR : Rerun mode has been requested but $previousDir does not exist, so the analysis has not started", 0);
  }

  # Read the last successful step from the file
  open ($stepFileHandle, '<', $stepFileName) or die "ERROR : $0 : cannot open file $stepFileName. $!\nExiting...\n";
  $lastOkStep = <$stepFileHandle>;
  close $stepFileHandle;

  toolbox::exportLog("INFO : Rerun mode enabled. Will resume after step $lastOkStep.", 1);
} else {
  #Reorganizing initial files
  toolbox::makeDir($previousDir);
  foreach my $currentFile (@$initialFileList)
  {
    my ($basicName) = toolbox::extractPath($currentFile);
    next if ($basicName =~ m/individuSoft|log\.[e|o]|Global_log$/); # Passing the individuSoft file
    my $mvCommand = "mv ".$currentFile." ".$previousDir."/".$basicName;
    toolbox::run($mvCommand,"noprint");
  }
}

my $optionRef=toolbox::readFileConf($fileConf); # Picking up the global options

my $hashOrder=toolbox::extractHashSoft($optionRef,"order"); #Picking up the options for the order of the pipeline

#########################################
# check if 1=processRadtags in $hashOrder
#########################################
$hashOrder = toolbox::rmHashOrder($hashOrder, "processRadtags");


#Global variables declaration

##FASTA associated variables
my $fastaFileIn="NA";
my $faidxFileOut="NA";
my $localFastaFileIn = "NA";
my $fastaFileOut = "NA";

##FASTQ associated variables
my ($fastqForwardIn, $fastqForwardOut, $fastqReverseIn, $fastqReverseOut)=("NA","NA","NA","NA");

##SAM associated variables
my ($samFileIn, $samFileOut)=("NA","NA"); #Those variables are to be used for sam standard but also if the block can treat SAM as well as BAM (eg samtools view)
## SAI associated variables
my ($saiForwardOut, $saiReverseOut)=("NA","NA"); # Use for bwa alnBlock, bwaSampe and bwaSamse

##BAM associated variables
my ($bamFileIn, $bamFileOut)=("NA","NA");
my $listOfBam=();

##VCF associated variables
my ($vcfFileIn,$vcfFileOut)=("NA","NA");

##Intervals/Report associated variables
my ($intervalsFile,$tableReport,$vcfSnpKnownFile,$depthFileOut);

##MpileUp associated variables
my ($mpileupOut);

##BED associated variables
my ($bedFileIn, $bedFileOut)=("NA","NA");

##BreakDancer and pindel associated variables
my ($cfgFile,$breakDancerOut, $pindelOut)=("NA","NA","NA");

##GENERIC variable
my ($fileIn,$fileOut)=("NA","NA");

##PED for SNIPLAY
my $pedFileIn = "NA";
my $phylipFileIn = "NA";
my $readseqFileIn = "NA";

##GTF for STRINGTIE
my $gtfFileIn = "NA";
my $gtfFileOut = "NA";
my $listOfGTF = ();

##Internal variables
###Directory and file variables
my ($newDir, $fileWithoutExtension, $extension, $shortDirName, @dirList, @fileList, $directory, $fileListMerge);
### Step variables
my ($stepF1, $stepOrder, $stepName, $softParameters);
### Various command variables
my ($cleanerCommand, $compressorCommand,$replacementCommand, $cmdMerge, $previousShortName,%stepDirectory);

my $fileList=toolbox::readDir($previousDir);
my $globalAnalysis=0; #to check if all data are to be treated one by one  (0) or in group (1)


if ($$fileList[0] !~ m/fasta|fastq|fq|fastq\.gz|fq\.gz|sam|bam|vcf|bai|vcf\.gz$|gtf$/)
{
  toolbox::exportLog("ERROR: The input files are not in a format usable by TOGGLE",0); # Not the good formats
}

if (scalar @$fileList >=2 && $$fileList[0] =~ m/(sam|bam|vcf|bai|vcf\.gz|gtf)$/)
{
  $globalAnalysis=1;
}

#Transfer to a node if the $scp provided in the config file
my $originalDir = $initialDir; #Keep in memory the true initial directory
if (defined $optionRef->{"scp"})
{
  if ($rerun)
  {
    toolbox::exportLog("ERROR: Rerunning an analysis with the \$scp option is not supported", 0)
    # TODO : Save the path of the remote folder here so that when resuming we can try to get the files on the node
  }
  #Picking up the "tmpRoot" info, ie the name of the temp dir on the nodes (eg /scratch, /tmp,...)
  my $scpOptions = toolbox::extractHashSoft($optionRef,"scp");
  my $tmpRoot = toolbox::extractOptions($scpOptions);
  #Launching transfer command and changing the $initialDir value
  my $refFastaFolder;
  ($initialDir,$refFastaFolder) = scp::transfer2node($originalDir,$tmpRoot,$readGroup);
  if (defined $refFastaFolder)
  {
    $refFastaFile = `basename $refFastaFile`;
    chomp $refFastaFile;
    $refFastaFile = $refFastaFolder."/".$refFastaFile;
  }

  $previousDir = $initialDir."/0_initialFiles";
  $fileList=toolbox::readDir($previousDir);
}

#Launching analysis, creating folder...

foreach my $position (sort {$a <=>$b} keys %{$hashOrder})
{
  if ($globalAnalysis == 0)
  {
    last if ($position >= 1000);
    my $directory = $initialDir."/".$position."_".$$hashOrder{$position};
    $directory =~ s/ //g; #Removing the spaces
    toolbox::makeDir($directory) unless $rerun; # Create the folder associated with each steps. The directory already exists if we are rerunning
    push (@dirList,$directory); # Adding the newly created folder to the list of folders
    $stepDirectory{$position} = $directory;
  }
  else
  {
    next if ($position < 1000);
    my $directory = $initialDir."/".$position."_".$$hashOrder{$position};
    $directory =~ s/ /_/g; #Removing the spaces
    toolbox::makeDir($directory); # Create the folder associated with each steps
    push (@dirList,$directory); # Adding the newly created folder to the list of folders
    $stepDirectory{$position} = $directory;

  }
}
